{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the glove.6B.zip from https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user gensim\n",
    "!pip install --user spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_vectors_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloads and installs you need to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import spacy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.50d.txt'\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.50d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('france', 'paris', 'russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('sweden', 'stockholm', 'norway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy('germany', 'berlin', 'austria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for pair in range(0, twodim.shape[0], 2):\n",
    "        plt.plot([twodim[pair,0], twodim[pair+1,0]], [twodim[pair,1], twodim[pair+1,1]], linewidth=1., c='b')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(model, ['france', 'paris', 'russia', 'moscow', 'finland', 'helsinki', 'sweden', 'stockholm', 'nepal', 'kathmandu', 'germany', 'berlin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(model, ['science', 'scientist', 'physics', 'physicist', 'chemistry', 'chemist', 'biology', 'biologist', 'mathematics', 'mathematician', 'art', 'painter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_lg = spacy.load(\"en_vectors_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_analogy(nlp, w1, w2, w3):\n",
    "    return nlp(w2).vector - nlp(w1).vector + nlp(w3).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the vocabulary for use in the distance function\n",
    "ids = [x for x in nlp_lg.vocab.vectors.keys()]\n",
    "vectors = [nlp_lg.vocab.vectors[x] for x in ids]\n",
    "vectors = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(nlp, w1, w2, w3):\n",
    "    vec = spacy_analogy(nlp, w1, w2, w3)\n",
    "    p = np.array([vec])\n",
    "    distances = distance.cdist(p, vectors, 'cosine')\n",
    "    distances = np.argsort(distances)\n",
    "    closest_index = distances[0][3]\n",
    "    word_id = ids[closest_index]\n",
    "    return nlp.vocab[word_id].text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(nlp_lg, 'france', 'paris', 'russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(nlp_lg, 'finland', 'helsinki', 'sweden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(nlp_lg, 'switzerland', 'bern', 'germany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_spacy_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab.strings ]\n",
    "    word_vectors = np.array([model(w).vector for w in words])\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for pair in range(0, twodim.shape[0], 2):\n",
    "        plt.plot([twodim[pair,0], twodim[pair+1,0]], [twodim[pair,1], twodim[pair+1,1]], linewidth=1., c='b')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_spacy_pca_scatterplot(nlp_lg, ['france', 'paris', 'russia', 'moscow', 'finland', 'helsinki', 'sweden', 'stockholm', 'armenia', 'yerevan', 'switzerland', 'bern', 'germany', 'berlin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_spacy_pca_scatterplot(nlp_lg, ['science', 'scientist', 'physics', 'physicist', 'biology', 'biologist', 'mathematics', 'mathematician', 'art', 'artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Play around with the analogies, add some more countries/capitals, see if they are still following the pattern.\n",
    "- In spacy analogy, change the distance from cosine to euclidean, what's the capital of Germany now?\n",
    "- Think of other type of analogies, let's say syntactic this time (past vs present of verbs, singular vs plular, etc.). See if the relationships hold.\n",
    "- Homework: Try to visualize three way relationships, like (take, took, taken), (shake, shook, shaken), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
