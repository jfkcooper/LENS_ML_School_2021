# LENS_ML_School_2021


A host for the tutorial material for the machine learning school 2021.
This school took place in the week commencing 15 Feburary 2021. Lecture recordings will soon be uploaded and links shared here. All resources can be run in a  Google colab environment.
<hr />

o  To use this material, if you are unfamiliar with git we reccommend donloading the entire repository (the green code button and download .zip file)  
o  To run the tutorials on colab (https://colab.research.google.com/) you will need a google acount, then select github when prompted for a notebook and insert this repository (https://github.com/jfkcooper/LENS_ML_School_2021) which should then find all of the notebooks   
o  Alot of the notebooks have "lecturer editions" with answers, or answers hidden at the bottom of the page if you get stuck  
o  A slack workspace has also been created for this school (https://join.slack.com/t/lensmlschool2021/shared_invite/zt-m5hi20cj-NoriZQbku~BuDQgge~BG8A) pleae join the conversation
<hr />



## Lecture 1: Introduction to deep learning and neural networks (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_1) (Jos Cooper)

o    Terminology

o    The perceptron

o    Fundamentals of deep learning: neural networks, nodes, weights, biases, activation functions,  backpropogation and some of the maths behind it

o    Introduction to Tensorflow, Pytorch, and Keras  

  


## Lecture 2: Dense neural networks and regression (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_2) (Jos Cooper) 

o    Supervised learning

o    Epochs, metrics, batch processing

o    Training, validation, testing, prediction  




## Lecture 3: Convolutional neural networks and classification (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_3)  (Emmanouela Rantsiou)

o    Filters, convolution, layers

o    Connections, activations, down sampling

o    Training, classification, metrics

o    Pre-processing

o    Augmentation, regularization

o    Hyper-parameter tuning

o    Transfer learning  





## Lecture 4: Traditional ML methods (https://mccluskey.scot/trad_ml_methods/intro.html) (Andrew McCluskey)

o    Decision trees

o    Gradient boosting

o    Principle component analysis (PCA)

o    Bayesian model selection  




## Lecture 5: Image segmentation (https://imaginglectures.github.io/MLSegmentation4NI/) (Anders Kaestner)

o    Object detection

o    Tomography

o    SegNet and/or ResNet

o    Semi-supervised learning  




## Lecture 6: Recurrent neural networks  (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lectures_6_8)  (Gagik Vardanyan)

o    Time series

o    Simple RNNs

o    LSTMs

o    GRUs  




## Lecture 7:Generative Adversarial Networks, GANs  (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_7)  (Kuangdai Leng)

o    Introduction to generative models: VAEs and GANs

o    GANs: basics and practice  
 



## Lecture 8: Natural language processing and speech recognition  (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lectures_6_8)  (Gagik Vardanyan & Guanghan Song)

o    Semantic spaaaaaace, word-to-vec

o    NNTK, spacey

o    Machine translation, seq-to-seq methods  





## Lecture 9: Uncertainty and attention  (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_9)  (Mario Teixeira Parente)

o    Bayesian methods 

o    Gaussian attention / spatial transformers  




## Lecture 10: Unsupervised learning - clustering  (https://github.com/jfkcooper/LENS_ML_School_2021/tree/main/lecture_10) (Marina Ganeva)

### Part 1

o   Introduction

o    Clustering

o    Manifold learning

### Part 2

o    Reinforcement learning  
  
